{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/schnecke/prot_xlstm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import EsmForProteinFolding\n",
    "\n",
    "from protxlstm.utils import load_sequences_from_msa_file, tokenizer, AA_TO_ID, reorder_masked_sequence, load_model\n",
    "from protxlstm.generation import generate_sequence\n",
    "from protxlstm.models.xlstm import xLSTMLMHeadModel\n",
    "from protxlstm.dataloaders import ProteinMemmapDataset\n",
    "\n",
    "from protxlstm.applications.generation_utils.score_hamming import align_sequences\n",
    "from protxlstm.applications.generation_utils.score_hmmer import make_hmm_from_a3m_msa, align_and_score_sequences_in_a3m_with_hmm\n",
    "from protxlstm.applications.generation_utils.score_structure import compute_structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please provide the path to your Prot-xLSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"../checkpoints/protxlstm_102M_60B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your context sequences either by providing a path to an MSA file or by entering a list of protein sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_path = \"./example_msas/A0A1C5UJ41.a3m\"\n",
    "\n",
    "# protein_list = [\"MRIDIDKFAGPCSCGREHEIDVKEIIIESGALKKLPEILSKYGLREYKNPAVICDTNTYAAAGELVEELLPRCEVIILDPEGLHADEHAVEKVMKQLDEDIDLLIAVGSGTIHDITRYCAYERGIPFISVPTAASVDGFVSTVAAMTWNGFKKTFPAVAPILVVADTDIFSKAPLRLTASGVGDILGKYIALADWKIAHLLTGEYICPEICDMEEKALDTVCSCLDGIAAGDEDAYEQLMYALILSGLAMQMVGNSRPASGAEHHMSHLWEMEVINGHIDALHGEKVGVGTVLVSDEYHKLAEAIRDGRCKVKPYMPLEEELLEETFGKKGLYEGILKENTPNPLEDVDPEMLEEKWPEIRDIIDELPSAEELRALLKKAGCKTTLEDIGLPESLKEETLRLSPYVRNRLTLMRLLKMLDFY\",\n",
    "#                 \"MTEIMENLSVDGISGAEIKCRCGKMHKNQIKEIIIERGALAKIPDIIKKHGGSNVYVIADRNTYAAAGETVCKNIERYNLPYSLYVFDSERIEPDELAVGKAIMHYDGKCDFIVGIGSGTINDIGKMVACITGKPYMIVATAPSMDGYASATSSMIRDGIKVSLGTVCPCVIVADTEVLCNAPKILLQAGIGDMLAKYISICEWRLSHLITGEYYCEEIASMVRNALKNCM-QIESLEFTEPDDIKPVIEGLIISGIAMSFAGLSRPASGMEHYFSHLWDMRAIEFNTPSALHGIQCGVATVLCLRVYEFIARLVPDRKKACDFVNSFSLKEWNRFLAGFLGRSAEGLIELERKERKYNPESHAKRLDIIVNNWDEIVKIISEELPPAEQVEKYMKKLGMPTMPKELGFSDGEVQGAFLATKDIRDKYIGSRLLWDLGLLDEAKHVCRSVW\",\n",
    "#                 \"MESKFSTTRVLPINQIFHLKQGVISAMMIDSKKYSGACACGHDHSMDTNLAVIQAGCLNQLDDYLQQFGLQGPRAAIYDENTYHAQGLVRPRAEQEIILAPENLHANEIAVEKVLSQLRGDIAILIAVGSGTIHDITRYCAHDRGILFISCPTAATVDGFCSTVSAMTWYGFKKTLPGVAPALVLADLNVICKAPAYLALSGVGDILGKYTALADWKISSAVSGEFFCPQIESMTRKAVQAVYQSARRLADRNEEAYEELTYGLLLSGLAMQLMGNSRPASGAEHHISHLIEMEPDGLGVHSNALHGEKVGAATLLVAREYHHLAETEDIAPHVHTYRFPDRYYLFPIFGERLTDAVSEENRDSCMKPVTPTALIEHWAEIRSIIAEIPAADELQSLYRDVGMKSTLADLGVPQSALPKLMEYSPCVRNRMTLMRIRRMIDLPYCE\",\n",
    "#                 \"MFEEILDVSGCACGKNHTLQTREYIVEKDAMKKLPALLARLFPSAKPLAVFDRNTHRAAYPKFGAALPEVPACILADDEIHADERQIDLVTQALRDGGHDLLLAVGSGVICDVVRYVAFKQELPFIVVPTAASVDGFVSNSAAMTLNGAKITLPAKAPNAVVADLEVVAAAPKKMTASGVGDMLSKYISIADWKIGHLITGEYFCPFVADLTIEAVDMIVQNIEKINSGDIDSFGILMKGLLLSGVAMQMVGITRPASSFEHHFSHYLEIVPVEGVNRAALHGEKVGIATIQAAKYYPIFARRLSRIYKENIPNQFDIERVKGYYAQYPAGIVAAIEKENTPTITAKLDRRLLEQNYDEVLRIAGEVPSAEALTETLRAIGGYTSYHDINMTDEQFKETMKVCCYIRNRFTLLRLVCDFALFDFDAELKV\",\n",
    "#                 \"MDVDLGHLSKPRVCGREHPDGIREIRIEPGATARLDDILLEYQYQNPVFICDSSTRAAAEPYLEEEFKDYLVIELDPTGLQADEASKQKILSQVEDCDLGLSSVPVDILVAIGAGTIHDLTRYAAEEFEIPFISVPTAASTDGFSCSMILRDPDGIRKEVPSVAPSWILADTNLFVHAPKRLTLAGVSDVISRLTALADWKVSHLVSDAWFDEEIYQEMRSRISRVIDQLEDICAGDVFATEALMDTLIYFGIMTGVPGENQAVCGAEHHVAHLWKMAVINPAPDALYGESVLTAMFLVLDQYKKMVPAIRQGKLRVDTEESKGIEYMLLERVFRDPEVLEQIIAENTPNPLEDIDLDAFEDSLEAIADVIDSLPRPDGLQRHLRAAGCRTALTQLGLPENIAALSLDAAPYLRGTITLLRLRKLLE\",\n",
    "#                 \"MRVDADDFARPCSCGREHQIAVKEILIEAGAVEKLEEEMSEGMLREYISPLVICDTNTYAATEprotein_listELMEDIYDRCQVLVLDAEGLQADRHAIKIVENNMEEDIDLILAVGAGTIHDISRYIAHNYKVPFISVPTAASGDGFVTTVAAITLDGVKKTVPSVAPICVYADTDIFSKAPQRLTAAGISDLMAKYICLADWKIANLVTGEYFCRETVKLEEKALKTVKSSIQDITEGEEDECEQLMYALILSGLAMQMIGNSRPASCAEHQVTHLWDMEVINGPLDALHGEKVSVAALLVLEEYKRIAAAITQGRCHAKPYENEDEELLKETFGKKGLLEEIRKENEPELLETISPQHLEKCLNGIEEIIDELPSEQTMFRLLEKAGCAKTVYDIGLDESAVLPSLRLAPYTRRRLSLLRISKMLDIRGE\",\n",
    "#                 \"MKIDANHLSGPCSCGGEHLLATQICVIQEGALFHLEEILSSIPVVGKRCAVYDENTYRAIPNSIHPRAEQEIILSPSGLHADENSTASVLARLEPDIQVMLAIGGGTVHDITRYCSTERGIPFISIPTAASCDGFCSNVAAMTWHGYKKTIPCQAPLLVVADLDVISAAPWRLTASGIGDMLGKFIALTDWRISHLLTGEKLCPVIYQIMEDAVDSIWTRCRDLRSGGSAAYEAVVYGLLMSGLAMQMIGTSRPASGAEHHVSHFIEVEPAALRTHSSALHGEKVGVGTLLIAQEYQRLSQIENIASLALPYAPVSDERLMEVFGPRLFSACREENLHDCLAQVTPERLIQQWPQIRQIIAKIPPAAQIHQFLTDLKASASLSDLGVPEAALELILEASPLIRNRLTFMRVRRIIRH\",\n",
    "#                 \"MIMDCAKYAGLCECGRDHELETKMVVVEYGAINNFEKYMADVGLAGKKRAVVYDSVIYKLTEGKHVAADQEIVLEAQGLRAEDTLIEDMMKKLDDPEVIVAYGAGTIMDFGRYPAYKLGIPFVAIPTLASSDGFTANICSAIINGQKKSTPMCAPTLVVTDLDIIKGAPMRLVSSGINDILSKYVSVFDWKVSHMVADEYFCPKVCELAEHALKIMRDAADKLAKTGEVDHEAMTMAQMESGLTMQLLNHSRAASGAEHLAAHLVEMHPPRFEEAEGIHGECVGVGTYLCIKEYHRLASLPTPKAKKFEPLSEEWIREKFGDRLAPGIIKENANDVLGTFDPQNIVDHWDEIRDMINKLPSAEEMEALYKACGCKYLPEHIGIKPELADEMLAVSSAIRNRNTLIRMRRVLDFGE\",\n",
    "#                 \"MQIDINSFRRPCNCGRTHEIFVKDILIEENALKRLPEKVRSIFDGRNTEIAVICDTNTYQAAGKTVEKLLPGCELIILPANDLRADNCGITLARKGLLSSGRIKLIIAAGAGTIHDISRYLAMEFRIPFVSVPTAASTDSYASVISILTMNGSKKNIPGDSPVLIIADTLILAKAPYRLTASGITKILRKYTALTDWEISHMVTGEYICQRICEMEMSALKEVCLYSNDLKGNTRDKNTLRAYEKLIYALLLSGIAMQMVGSISSASGGDDAAHLWEKEAVNELFETYHGEKISIGLMVAVHTCHKLKNTVKNGINKVMPNREIESMGKGRTYEEVVKENALDSLPAISGILGKLPTESDLRKLLTAAGYKREIRDIKLEERLVPLTKRLDFDTRNRLIFLKFTKFFKLKNEA\",\n",
    "#                 \"MNKPSTEKIVINGGCAAECRSYAREHFGDAYAVVCDGNTEPIARRAFPGDELIVFPAGSHATEQAADDCISRIKSDELCGLIACGSGSVHDIARYSAHDRKIPFVSFPTAASVDGFASGVAAMTWHGRKVTFPSAPPIALFADDDVYSSAPRELLASGVGDIVGKYVSIFDWIFTSLLTSETVEDDIYKLENESLETVMHCDISSPDYPHGVMDCLVKSGIAIQLKDSSRPASGAEHHLSHLWEMGCIGTPKHAYHGEQVGVSTLFVLDRYKRNPRPQLRPKPLDRELLRPTFGTLTDGIIEENTPDSLAEITQSALDANADRIAELIKALPDPEEIREYLLSVGAKTTLTELGLPDSTEFIQRSLDWAPYVRRRLTYLKVI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your sampling parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sequences to sample as context; if set to -1 all sequences provided above are used\n",
    "num_context_sequences = 100\n",
    "# number of sequences to generate\n",
    "num_sequences = 10  \n",
    "\n",
    "# controls the randomness of the model’s output; the higher the more diverse\n",
    "temperature = 0.9  \n",
    "# limits the model's choices to the top k most likely next tokens\n",
    "top_k = 10\n",
    "# limits the model's choices smallest set of next tokens whose cumulative probability exceeds p\n",
    "top_p = 0.9  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read msa file\n",
    "if msa_path != None:\n",
    "    msa_sequences = load_sequences_from_msa_file(msa_path)\n",
    "    protein_list = [msa.upper() for msa in msa_sequences]\n",
    "\n",
    "# tokenize context sequences\n",
    "tokens = tokenizer(protein_list, concatenate=True)\n",
    "\n",
    "# load data class\n",
    "data_class = ProteinMemmapDataset(\n",
    "        sample=False,\n",
    "        max_msa_len=-1,\n",
    "        reverse=False,\n",
    "        seed=0,\n",
    "        troubleshoot=False,\n",
    "        fim_strategy=\"multiple_span\",\n",
    "        always_mask=False,\n",
    "        max_position_embeddings=2048,\n",
    "        max_seq_position_embeddings=512,\n",
    "        add_position_ids=\"1d\",\n",
    "        mask_fraction=0.2,\n",
    "        max_patches=5\n",
    "    )\n",
    "\n",
    "# get number of context sequences\n",
    "if num_context_sequences == -1:\n",
    "    num_context_sequences = len(protein_list)\n",
    "else:\n",
    "    num_context_sequences = min(num_context_sequences, len(protein_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detected slstm_block\n",
      "In newest xlstm\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "config_update_kwargs = {\n",
    "                \"mlstm_backend\": \"chunkwise_variable\",\n",
    "                \"mlstm_chunksize\": 1024,\n",
    "                \"mlstm_return_last_state\": True}\n",
    "\n",
    "model = load_model(checkpoint,\n",
    "                    model_class=xLSTMLMHeadModel,\n",
    "                    device=device,\n",
    "                    dtype=torch.bfloat16,\n",
    "                    **config_update_kwargs,\n",
    "                    )\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_2138762/1850560979.py:32: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  generation_df = pd.concat([generation_df, pd.DataFrame({'Generated Sequence': [reorder_masked_sequence(output[\"generated\"][0])], 'Perplexity': [perplexity]})], ignore_index=True)\n",
      "100%|██████████| 10/10 [01:19<00:00,  7.95s/it]\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe for the results\n",
    "generation_df = pd.DataFrame(columns = ['Generated Sequence', 'Perplexity'])\n",
    "\n",
    "for i in tqdm(range(num_sequences)):\n",
    "\n",
    "    # sample context sequences and corresponding positional embeddings\n",
    "    input_ids, pos_ids = data_class.sample_sequences(tokens.numpy()[0], num_sequences=num_context_sequences)\n",
    "    input_ids.append(AA_TO_ID[\"<cls>\"])\n",
    "    input_ids = torch.asarray(input_ids, dtype=torch.int64)[None,:].to(device)\n",
    "    pos_ids.append(0)\n",
    "    pos_ids = torch.asarray(pos_ids, dtype=torch.int64)[None,:].to(device)\n",
    "\n",
    "    # generate sequences\n",
    "    output = generate_sequence(model,\n",
    "                                input_ids,\n",
    "                                position_ids=pos_ids,\n",
    "                                is_fim={},\n",
    "                                max_length=(input_ids.shape[1]+1000),\n",
    "                                temperature=temperature,\n",
    "                                top_k=top_k,\n",
    "                                top_p=top_p,\n",
    "                                return_dict_in_generate=True,\n",
    "                                output_scores=True,\n",
    "                                eos_token_id=torch.tensor([AA_TO_ID[\"<cls>\"]]).to(device),\n",
    "                                chunk_chunk_size=2**15,\n",
    "                                device=device)\n",
    "    \n",
    "    # calculate perplexity\n",
    "    perplexity = float(torch.exp(torch.nn.functional.cross_entropy(torch.from_numpy(output[\"scores\"]).permute(0, 2, 1), torch.from_numpy(output[\"generated_tokens\"][0][None,:]))))\n",
    "    \n",
    "    # append sequence and perplexity to data frame\n",
    "    generation_df = pd.concat([generation_df, pd.DataFrame({'Generated Sequence': [reorder_masked_sequence(output[\"generated\"][0])], 'Perplexity': [perplexity]})], ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Sequence</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VLLVSDTGILNSGVLERIREKLKGLGIKVELFPLPESEPTFQQVEK...</td>\n",
       "      <td>4.358632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PVTVLSGPDAIARVGDELVEAGAKKALVVTGARAVDHCGVLDALAA...</td>\n",
       "      <td>3.335460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VPATTTTATRRLALGEGALGRVPAVLDALGGRPLLVLADAGVAAAA...</td>\n",
       "      <td>4.730563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IVSGPGARAAVGDLVAEHGGSRVLVITDPGVAGAGLAPALTGVLEG...</td>\n",
       "      <td>3.036892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KPTTVIYDQKALEELEELVEKNGFERPLLVTGRGSFKKSGVYENVM...</td>\n",
       "      <td>3.524508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MVTDDTTYAAAAAVVEGLGITAEAIDVAGEGDRKDLTTVDRVWRAA...</td>\n",
       "      <td>3.225808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRIIFGEGAADRAAGYLKSFGKKVFIVTGKGSIKNSGAYDLVSKTL...</td>\n",
       "      <td>3.018368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TVSAVESGALAELRGELRDLGAGRVVLVTDENTARSYGERVRETLG...</td>\n",
       "      <td>3.241559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SASIEALDAALAERGGGLLLVDSGVLSRLPEELARASRVRGLELAP...</td>\n",
       "      <td>3.711276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSTVHVATGEIAEVLRDLEDAGRERLVVVTDAGLRDAGVAGRVRAV...</td>\n",
       "      <td>3.514427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Generated Sequence  Perplexity\n",
       "0  VLLVSDTGILNSGVLERIREKLKGLGIKVELFPLPESEPTFQQVEK...    4.358632\n",
       "1  PVTVLSGPDAIARVGDELVEAGAKKALVVTGARAVDHCGVLDALAA...    3.335460\n",
       "2  VPATTTTATRRLALGEGALGRVPAVLDALGGRPLLVLADAGVAAAA...    4.730563\n",
       "3  IVSGPGARAAVGDLVAEHGGSRVLVITDPGVAGAGLAPALTGVLEG...    3.036892\n",
       "4  KPTTVIYDQKALEELEELVEKNGFERPLLVTGRGSFKKSGVYENVM...    3.524508\n",
       "5  MVTDDTTYAAAAAVVEGLGITAEAIDVAGEGDRKDLTTVDRVWRAA...    3.225808\n",
       "6  PRIIFGEGAADRAAGYLKSFGKKVFIVTGKGSIKNSGAYDLVSKTL...    3.018368\n",
       "7  TVSAVESGALAELRGELRDLGAGRVVLVTDENTARSYGERVRETLG...    3.241559\n",
       "8  SASIEALDAALAERGGGLLLVDSGVLSRLPEELARASRVRGLELAP...    3.711276\n",
       "9  MSTVHVATGEIAEVLRDLEDAGRERLVVVTDAGLRDAGVAGRVRAV...    3.514427"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(generation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Hamming distances to context sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "# create new column in dataframe\n",
    "generation_df[\"Minimum Hamming Distance\"] = pd.Series()\n",
    "\n",
    "for i in tqdm(range(len(generation_df))):\n",
    "\n",
    "    # calculate pairwise Hamming distances to all context sequences\n",
    "    all_hamming = []\n",
    "    for ctx_seq in protein_list:\n",
    "        hamming, _, _ = align_sequences(ctx_seq, generation_df[\"Generated Sequence\"].iloc[i], print_alignments=False)\n",
    "        all_hamming.append(hamming)\n",
    "\n",
    "    # add the Hamming distance to the closest context sequence to the data frame\n",
    "    min_hamming = np.mean(all_hamming)\n",
    "    generation_df.loc[i, \"Minimum Hamming Distance\"] = min_hamming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate HMMER scores (only if an MSA is available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not msa_path == None:\n",
    "\n",
    "    # train HMM\n",
    "    hmm = make_hmm_from_a3m_msa(msa_path)\n",
    "    \n",
    "    # score all sequences\n",
    "    scores = align_and_score_sequences_in_a3m_with_hmm(hmm, sequences_list=list(generation_df[\"Generated Sequence\"]))\n",
    "\n",
    "    # add HMMER scores to the data frame\n",
    "    for seq in list(generation_df[\"Generated Sequence\"]):\n",
    "        generation_df.loc[generation_df[\"Generated Sequence\"] == seq, \"HMMER Score\"] = scores[seq][\"score\"] if seq in scores.keys() else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate folding scores (pTM and PLDDT) using ESMFold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForProteinFolding were not initialized from the model checkpoint at facebook/esmfold_v1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 10/10 [01:35<00:00,  9.55s/it]\n"
     ]
    }
   ],
   "source": [
    "# import the folding model\n",
    "model = EsmForProteinFolding.from_pretrained(\"facebook/esmfold_v1\", cache_dir=\"/system/user/publicdata/pxlstm_temp/esm-fold\", low_cpu_mem_usage=True)\n",
    "model = model.cuda(device)\n",
    "model.esm = model.esm.half()\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "for seq in tqdm(list(generation_df[\"Generated Sequence\"])):\n",
    "\n",
    "    # compute structural scores\n",
    "    ptm, pae, mean_plddt, pos_plddt = compute_structure(seq, model)\n",
    "    \n",
    "    # add scores to the data frame\n",
    "    generation_df.loc[generation_df[\"Generated Sequence\"] == seq, \"pTM\"] = ptm\n",
    "    generation_df.loc[generation_df[\"Generated Sequence\"] == seq, \"Mean pLDDT\"] = mean_plddt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Sequence</th>\n",
       "      <th>Perplexity</th>\n",
       "      <th>Minimum Hamming Distance</th>\n",
       "      <th>HMMER Score</th>\n",
       "      <th>pTM</th>\n",
       "      <th>Mean pLDDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VLLVSDTGILNSGVLERIREKLKGLGIKVELFPLPESEPTFQQVEK...</td>\n",
       "      <td>4.358632</td>\n",
       "      <td>0.614762</td>\n",
       "      <td>217.472214</td>\n",
       "      <td>0.961031</td>\n",
       "      <td>0.911549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PVTVLSGPDAIARVGDELVEAGAKKALVVTGARAVDHCGVLDALAA...</td>\n",
       "      <td>3.335460</td>\n",
       "      <td>0.620925</td>\n",
       "      <td>232.497360</td>\n",
       "      <td>0.964514</td>\n",
       "      <td>0.930103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VPATTTTATRRLALGEGALGRVPAVLDALGGRPLLVLADAGVAAAA...</td>\n",
       "      <td>4.730563</td>\n",
       "      <td>0.722965</td>\n",
       "      <td>173.413864</td>\n",
       "      <td>0.679946</td>\n",
       "      <td>0.589188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IVSGPGARAAVGDLVAEHGGSRVLVITDPGVAGAGLAPALTGVLEG...</td>\n",
       "      <td>3.036892</td>\n",
       "      <td>0.551833</td>\n",
       "      <td>150.928665</td>\n",
       "      <td>0.959316</td>\n",
       "      <td>0.943711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KPTTVIYDQKALEELEELVEKNGFERPLLVTGRGSFKKSGVYENVM...</td>\n",
       "      <td>3.524508</td>\n",
       "      <td>0.612628</td>\n",
       "      <td>281.122864</td>\n",
       "      <td>0.956960</td>\n",
       "      <td>0.916718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MVTDDTTYAAAAAVVEGLGITAEAIDVAGEGDRKDLTTVDRVWRAA...</td>\n",
       "      <td>3.225808</td>\n",
       "      <td>0.555919</td>\n",
       "      <td>139.610992</td>\n",
       "      <td>0.939767</td>\n",
       "      <td>0.912960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRIIFGEGAADRAAGYLKSFGKKVFIVTGKGSIKNSGAYDLVSKTL...</td>\n",
       "      <td>3.018368</td>\n",
       "      <td>0.660326</td>\n",
       "      <td>296.930481</td>\n",
       "      <td>0.937441</td>\n",
       "      <td>0.879868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TVSAVESGALAELRGELRDLGAGRVVLVTDENTARSYGERVRETLG...</td>\n",
       "      <td>3.241559</td>\n",
       "      <td>0.620738</td>\n",
       "      <td>274.203796</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.942209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SASIEALDAALAERGGGLLLVDSGVLSRLPEELARASRVRGLELAP...</td>\n",
       "      <td>3.711276</td>\n",
       "      <td>0.593117</td>\n",
       "      <td>123.156120</td>\n",
       "      <td>0.898233</td>\n",
       "      <td>0.863185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSTVHVATGEIAEVLRDLEDAGRERLVVVTDAGLRDAGVAGRVRAV...</td>\n",
       "      <td>3.514427</td>\n",
       "      <td>0.619098</td>\n",
       "      <td>223.633408</td>\n",
       "      <td>0.962831</td>\n",
       "      <td>0.923391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Generated Sequence  Perplexity  \\\n",
       "0  VLLVSDTGILNSGVLERIREKLKGLGIKVELFPLPESEPTFQQVEK...    4.358632   \n",
       "1  PVTVLSGPDAIARVGDELVEAGAKKALVVTGARAVDHCGVLDALAA...    3.335460   \n",
       "2  VPATTTTATRRLALGEGALGRVPAVLDALGGRPLLVLADAGVAAAA...    4.730563   \n",
       "3  IVSGPGARAAVGDLVAEHGGSRVLVITDPGVAGAGLAPALTGVLEG...    3.036892   \n",
       "4  KPTTVIYDQKALEELEELVEKNGFERPLLVTGRGSFKKSGVYENVM...    3.524508   \n",
       "5  MVTDDTTYAAAAAVVEGLGITAEAIDVAGEGDRKDLTTVDRVWRAA...    3.225808   \n",
       "6  PRIIFGEGAADRAAGYLKSFGKKVFIVTGKGSIKNSGAYDLVSKTL...    3.018368   \n",
       "7  TVSAVESGALAELRGELRDLGAGRVVLVTDENTARSYGERVRETLG...    3.241559   \n",
       "8  SASIEALDAALAERGGGLLLVDSGVLSRLPEELARASRVRGLELAP...    3.711276   \n",
       "9  MSTVHVATGEIAEVLRDLEDAGRERLVVVTDAGLRDAGVAGRVRAV...    3.514427   \n",
       "\n",
       "  Minimum Hamming Distance  HMMER Score       pTM  Mean pLDDT  \n",
       "0                 0.614762   217.472214  0.961031    0.911549  \n",
       "1                 0.620925   232.497360  0.964514    0.930103  \n",
       "2                 0.722965   173.413864  0.679946    0.589188  \n",
       "3                 0.551833   150.928665  0.959316    0.943711  \n",
       "4                 0.612628   281.122864  0.956960    0.916718  \n",
       "5                 0.555919   139.610992  0.939767    0.912960  \n",
       "6                 0.660326   296.930481  0.937441    0.879868  \n",
       "7                 0.620738   274.203796  0.971223    0.942209  \n",
       "8                 0.593117   123.156120  0.898233    0.863185  \n",
       "9                 0.619098   223.633408  0.962831    0.923391  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(generation_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prot_xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
